{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.   0.   0.   0.]\n",
      " [ -4.   1.   0.   0.]\n",
      " [ -1.  -3.   0.   0.]\n",
      " [  0.   0.   2. -10.]]\n"
     ]
    }
   ],
   "source": [
    "# Initial weights\n",
    "W = np.array([[3.0,0.0,0.0,0.0],[-4.0,1.0,0.0,0.0],[-1.0,-3.0,0.0,0.0],[0.0,0.0,2.0,-10.0]])\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definition of activation functions\n",
    "def relu(x):\n",
    "    fx = 0.0\n",
    "    if x >= 0.0:\n",
    "        fx = x\n",
    "    return fx\n",
    "\n",
    "# relu vectorized\n",
    "v_relu = np.vectorize(relu)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "# sigmoid vectorized\n",
    "v_sigmoid = np.vectorize(sigmoid)\n",
    "\n",
    "# Forward propagation vectorized\n",
    "def v_fpropagation(W,X):\n",
    "    # first layer\n",
    "    W1 = W[[3],2:4:1]\n",
    "    a3a4 = X.dot(W1)\n",
    "    z3z4 = v_sigmoid(a3a4)\n",
    "    # second layer\n",
    "    W2 = W[1:3:1,[1]]\n",
    "    a2 = z3z4.dot(W2)\n",
    "    z2 = v_relu(a2)\n",
    "    # third layer\n",
    "    W3 = W[0:3:1,[0]]\n",
    "    z2z3z4 = np.append(z2,z3z4,axis=1)\n",
    "    a1 = z2z3z4.dot(W3)\n",
    "    y = v_sigmoid(a1)\n",
    "    return [y,a1,z2,a2,z3z4,a3a4]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propagation on the vector $X = \\begin{bmatrix}0.0\\\\ 1.0\\\\ \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " [[ 0.]\n",
      " [ 1.]]\n",
      "Output:\n",
      " [array([[ 0.07585818],\n",
      "       [ 0.2929186 ]]), array([[-2.5       ],\n",
      "       [-0.88125106]]), array([[ 0.        ],\n",
      "       [ 0.88066088]]), array([[-1.        ],\n",
      "       [ 0.88066088]]), array([[  5.00000000e-01,   5.00000000e-01],\n",
      "       [  8.80797078e-01,   4.53978687e-05]]), array([[  0.,  -0.],\n",
      "       [  2., -10.]])]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0.0],[1.0]])\n",
    "print(\"Input:\\n\",X)\n",
    "fnn = v_fpropagation(W,X)\n",
    "print(\"Output:\\n\",fnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definition of step function modified at zero\n",
    "def step(x):\n",
    "    fx = 0.0 # take this as the derivative of relu at 0\n",
    "    if x > 0:\n",
    "        fx = 1.0\n",
    "    return fx\n",
    "\n",
    "# Step vectorized\n",
    "v_step = np.vectorize(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definition of the errors function (calculate the deltas)\n",
    "def v_deltas(W,X,t):\n",
    "    [y,a1,z2,a2,z3z4,a3a4] = v_fpropagation(W,X)\n",
    "    delta1 = -(t-y)*y*(1-y)\n",
    "    bW1 = W[[0],0] # w2_1\n",
    "    delta2 = delta1*bW1*v_step(a2)\n",
    "    delta1d2 = np.append(delta1,delta2,axis=1)\n",
    "    bW2 = W[[1,2],0:2:1].transpose() #[[w3_1,w4_1],[w3_2,w4_2]]\n",
    "    delta3d4 = delta1d2.dot(bW2)*v_sigmoid(a3a4)*(1-v_sigmoid(a3a4))\n",
    "    bW3 = W[[3],2:4:1].transpose()\n",
    "    delta5 = delta3d4.dot(bW3)\n",
    "    return [delta1,delta2,delta3d4,delta5,y,a1,z2,a2,z3z4,a3a4]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets:\n",
      " [[ 0.5]\n",
      " [ 0.1]]\n",
      "Deltas:\n",
      " [array([[-0.02973392],\n",
      "       [ 0.03995678]]), array([[-0.        ],\n",
      "       [ 0.11987033]]), array([[  2.97339179e-02,   7.43347948e-03],\n",
      "       [ -4.19520531e-03,  -1.81387018e-05]]), array([[-0.01486696],\n",
      "       [-0.00820902]]), array([[ 0.07585818],\n",
      "       [ 0.2929186 ]]), array([[-2.5       ],\n",
      "       [-0.88125106]]), array([[ 0.        ],\n",
      "       [ 0.88066088]]), array([[-1.        ],\n",
      "       [ 0.88066088]]), array([[  5.00000000e-01,   5.00000000e-01],\n",
      "       [  8.80797078e-01,   4.53978687e-05]]), array([[  0.,  -0.],\n",
      "       [  2., -10.]])]\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[.5],[.1]])\n",
    "print(\"Targets:\\n\",t)\n",
    "bdeltas = v_deltas(W,X,t)\n",
    "print(\"Deltas:\\n\",bdeltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss(W,X,t):\n",
    "    fnn = v_fpropagation(W,X)\n",
    "    y = fnn[0]\n",
    "    E = np.sum(np.square(t-y))/2\n",
    "    return E\n",
    "\n",
    "# Function to train the network using Stochastic Gradient Descent (SGD)\n",
    "def SGD(X,t,eta):\n",
    "    # Number of training samples\n",
    "    m = len(t)\n",
    "    # Initialize the weights W\n",
    "    W = np.sqrt(2)*np.random.randn(4,4)\n",
    "    multW = np.array([[1.,0.,0.,0.],[1.,1.,0.,0.],[1.,1.,0.,0.],[0.,0.,1.,1.]]) # multiply and get zeros where needed\n",
    "    W = W*multW\n",
    "    #W = np.array([[3.0,0.0,0.0,0.0],[-4.0,1.0,0.0,0.0],[-1.0,-3.0,0.0,0.0],[0.0,0.0,2.0,-10.0]])\n",
    "    # print loss and weights\n",
    "    print(\"Loss at the beginning: %f\" %loss(W,X,t))\n",
    "    print(W)\n",
    "    # vector to store loss at iteration i\n",
    "    L = []\n",
    "    # SGD\n",
    "    # random permutation of indices\n",
    "    ind = np.random.permutation(m)\n",
    "    for i in range(0,m):\n",
    "        # fpropagation, deltas and bpropagation calculated on sample i only\n",
    "        [delta1,delta2,delta3d4,delta5,y,a1,z2,a2,z3z4,a3a4] = v_deltas(W,X[[ind[i]]],t[[ind[i]]])\n",
    "        dw2_1 = delta1*z2\n",
    "        dw3n4_1 = delta1*z3z4\n",
    "        dw3n4_2 = delta2*z3z4\n",
    "        dw5_3n4 = delta3d4*X[[ind[i]]]\n",
    "        \n",
    "        # parameter update\n",
    "        W[0,0] += -eta*dw2_1\n",
    "        W[1:3:1,[0]] += -eta*dw3n4_1.transpose()\n",
    "        W[1:3:1,[1]] += -eta*dw3n4_2.transpose()\n",
    "        W[[3],2:4:1] += -eta*dw5_3n4\n",
    "        \n",
    "        # print loss and weights\n",
    "        L.append(loss(W,X,t))\n",
    "        if L[i] < 0.01:\n",
    "            return W, L\n",
    "        print(\"Loss after iteration %i: %f\" %(i, L[i]))\n",
    "        print(W)\n",
    "    \n",
    "    L = np.array(L)\n",
    "    return W, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training samples\n",
    "trainX = np.array([[-3.],[-2.],[-1.5],[-1.],[-.5],[0.],[.5],[1.],[1.5],[2.],[3.]])\n",
    "traint = np.array([[.7312],[.7339],[.7438],[.7832],[.8903],[.9820],[.8114],[.5937],[.5219],[.5049],[.5002]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at the beginning: 1.598042\n",
      "[[-1.3587122   0.          0.          0.        ]\n",
      " [-2.21111822 -0.80143146 -0.          0.        ]\n",
      " [-0.47101429  0.06698397  0.          0.        ]\n",
      " [ 0.          0.         -1.52491538  1.97349581]]\n",
      "Loss after iteration 0: 1.116756\n",
      "[[-1.3587122   0.          0.          0.        ]\n",
      " [-1.57454845 -0.80143146 -0.          0.        ]\n",
      " [ 0.16555548  0.06698397  0.          0.        ]\n",
      " [ 0.          0.         -1.52491538  1.97349581]]\n",
      "Loss after iteration 1: 0.698224\n",
      "[[-1.3587122   0.          0.          0.        ]\n",
      " [-0.78204585 -0.80143146 -0.          0.        ]\n",
      " [ 0.16769865  0.06698397  0.          0.        ]\n",
      " [ 0.          0.         -1.48671771  1.97243422]]\n",
      "Loss after iteration 2: 0.299130\n",
      "[[-1.3587122   0.          0.          0.        ]\n",
      " [ 0.03183913 -0.80143146 -0.          0.        ]\n",
      " [ 0.49393469  0.06698397  0.          0.        ]\n",
      " [ 0.          0.         -1.384156    1.95251072]]\n",
      "Loss after iteration 3: 0.164363\n",
      "[[-1.3587122   0.          0.          0.        ]\n",
      " [ 0.5434334  -0.80143146 -0.          0.        ]\n",
      " [ 0.5231538   0.06698397  0.          0.        ]\n",
      " [ 0.          0.         -1.38687854  1.93196088]]\n",
      "Loss after iteration 4: 0.118528\n",
      "[[-1.3587122   0.          0.          0.        ]\n",
      " [ 0.84515319 -0.80143146 -0.          0.        ]\n",
      " [ 0.57087038  0.06698397  0.          0.        ]\n",
      " [ 0.          0.         -1.41965614  1.91015644]]\n",
      "Loss after iteration 5: 0.121689\n",
      "[[-1.3587122   0.          0.          0.        ]\n",
      " [ 0.95163175 -0.80143146 -0.          0.        ]\n",
      " [ 0.80413293  0.06698397  0.          0.        ]\n",
      " [ 0.          0.         -1.38949291  1.92865704]]\n",
      "Loss after iteration 6: 0.113655\n",
      "[[-1.37984516  0.          0.          0.        ]\n",
      " [ 0.94572937 -0.79341181 -0.          0.        ]\n",
      " [ 0.41802094  0.59159904  0.          0.        ]\n",
      " [ 0.          0.         -1.42507455  1.92612861]]\n",
      "Loss after iteration 7: 0.081093\n",
      "[[-1.30582485  0.          0.          0.        ]\n",
      " [ 0.98531119 -0.8480286  -0.          0.        ]\n",
      " [ 0.59622439  0.34570587  0.          0.        ]\n",
      " [ 0.          0.         -1.35996539  1.91710173]]\n",
      "Loss after iteration 8: 0.096945\n",
      "[[-1.34966699  0.          0.          0.        ]\n",
      " [ 0.97583566 -0.83565522 -0.          0.        ]\n",
      " [ 0.44616141  0.54166184  0.          0.        ]\n",
      " [ 0.          0.         -1.39717283  1.91618215]]\n",
      "Loss after iteration 9: 0.093470\n",
      "[[-1.34966699  0.          0.          0.        ]\n",
      " [ 1.00838176 -0.83565522 -0.          0.        ]\n",
      " [ 0.44689356  0.54166184  0.          0.        ]\n",
      " [ 0.          0.         -1.40083348  1.91554269]]\n",
      "Loss after iteration 10: 0.078838\n",
      "[[-1.31706287  0.          0.          0.        ]\n",
      " [ 1.01680883 -0.84702895 -0.          0.        ]\n",
      " [ 0.52008726  0.44287471  0.          0.        ]\n",
      " [ 0.          0.         -1.37677286  1.91387389]]\n"
     ]
    }
   ],
   "source": [
    "# Learning rate eta\n",
    "eta = 10\n",
    "# training the nn\n",
    "Wmodel, Loss = SGD(trainX,traint,eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73152693]\n",
      " [ 0.72451931]\n",
      " [ 0.71713057]\n",
      " [ 0.70656289]\n",
      " [ 0.69447318]\n",
      " [ 0.68318508]\n",
      " [ 0.66091854]\n",
      " [ 0.59258358]\n",
      " [ 0.54491367]\n",
      " [ 0.51645451]\n",
      " [ 0.49268486]]\n"
     ]
    }
   ],
   "source": [
    "# check predictions of the model on training samples\n",
    "fnn = v_fpropagation(Wmodel,trainX)\n",
    "print(fnn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10c7950f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEKCAYAAADticXcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c3fe710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of evolution of errors\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Loss)\n",
    "plt.title(\"Loss vs. Iteration No.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
